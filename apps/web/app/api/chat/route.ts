import { NextRequest, NextResponse } from 'next/server'
import { MODELS } from '@/lib/models'
import { getTier } from '@/lib/orchestrator'

export const dynamic = 'force-dynamic'
export const runtime = 'edge'

async function callModel(modelId: string, prompt: string, systemPrompt?: string, fallbackModelId?: string): Promise<string> {
  const API_KEY = process.env.OPENROUTER_API_KEY || ''
  
  const modelsToTry = [modelId];
  if (fallbackModelId) {
    modelsToTry.push(fallbackModelId);
  }

  let lastError: Error | null = null;

  for (const currentModelId of modelsToTry) {
    try {
      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${API_KEY}`,
      'Content-Type': 'application/json',
      'HTTP-Referer': 'https://clashof.ai',
      'X-Title': 'Clash of AI'
    },
    body: JSON.stringify({
      model: modelId,
      messages: [
        ...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
        { role: 'user', content: prompt }
      ],
      stream: false,
    }),
  });
  
  const data = await response.json();

  if (!response.ok) {
    // OpenRouter'dan gelen hata mesajÄ±nÄ± yakala
    const errorMessage = data.error ? data.error.message : `HTTP Error ${response.status}`;
    throw new Error(`OpenRouter Error: ${errorMessage}`);
  }
  
  if (!data.choices || data.choices.length === 0) {
    throw new Error('OpenRouter Error: Model yanÄ±t vermedi veya boÅŸ bir seÃ§im listesi dÃ¶ndÃ¼rdÃ¼.');
  }

  return data.choices[0].message.content;
} catch (error: any) {
      lastError = error;
      console.error(`Model ${currentModelId} failed. Trying fallback if available. Error: ${error.message}`);
      // EÄŸer bu son denemeyse, hatayÄ± fÄ±rlat
      if (currentModelId === modelsToTry[modelsToTry.length - 1]) {
        throw lastError;
      }
      // Aksi takdirde, bir sonraki modele geÃ§
    }
  }

  // Bu kÄ±sma normalde ulaÅŸÄ±lmamalÄ±, ancak TypeScript'i mutlu etmek iÃ§in
  if (lastError) {
    throw lastError;
  }
  throw new Error('TÃ¼m model denemeleri baÅŸarÄ±sÄ±z oldu.');
}

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { messages } = body;
    const lastMessage = messages[messages.length - 1].content;
    
    const tier = getTier(lastMessage);
    
    if (tier === 'T1') {
      const response = await callModel(MODELS.fastWorker, lastMessage, undefined, MODELS.fastWorker); // T1'de fallback'e gerek yok, zaten en hÄ±zlÄ± model
      return NextResponse.json({
        tier: 'T1',
        responses: [{ type: 'normal', model: 'DeepSeek', content: response }]
      });
    }
    
    if (tier === 'T2') {
      const mainResponse = await callModel(
        MODELS.architect, 
        lastMessage, 
        "You are the Architect. Provide a detailed and structured answer.",
        MODELS.fastWorker // Architect iÃ§in fallback
      );
      
      const interjection = await callModel(
        MODELS.prosecutor,
        `User Question: ${lastMessage}\nArchitect's Answer: ${mainResponse}\n\nTask: Critically analyze the answer. If there is a mistake, a better approach, or a missing constraint, provide a VERY SHORT note (max 2 sentences). If the answer is perfect, reply ONLY with 'OK'.`,
        "You are the Prosecutor. Be critical and concise."
      );
      
      const responses = [
        { type: 'normal', model: 'Claude', content: mainResponse }
      ];
      
      if (interjection.trim().toUpperCase() !== 'OK') {
        responses.push({ type: 'info', model: 'Prosecutor', content: interjection });
      }
      
      return NextResponse.json({ tier: 'T2', responses });
    }

    if (tier === 'T2.5') {
      const thesis = await callModel(
        MODELS.architect,
        lastMessage,
        "You are the Architect. Your role is to present a strong THESIS (ğŸ›¡ï¸). Provide a clear and well-supported argument.",
        MODELS.fastWorker // Architect iÃ§in fallback
      );

      const antithesis = await callModel(
        MODELS.prosecutor,
        `User Question: ${lastMessage}\n\nğŸ›¡ï¸ THESIS TO CHALLENGE:\n${thesis}\n\nTask: Present a strong ANTITHESIS (âš”ï¸). Do NOT repeat the thesis. Challenge its weaknesses and offer a compelling counter-argument.`,
        "You are the Prosecutor. Be sharp and provide a strong counter-view."
      );

      return NextResponse.json({
        tier: 'T2.5',
        responses: [
          { type: 'thesis', model: 'Claude', content: thesis },
          { type: 'antithesis', model: 'DeepSeek-R', content: antithesis }
        ]
      });
    }

    if (tier === 'T3') {
      const thesis = await callModel(
        MODELS.architect,
        lastMessage,
        "You are the Architect. Present a deep and comprehensive THESIS (ğŸ›¡ï¸). Consider all major factors.",
        MODELS.fastWorker // Architect iÃ§in fallback
      );

      const antithesis = await callModel(
        MODELS.prosecutor,
        `User Question: ${lastMessage}\n\nğŸ›¡ï¸ THESIS TO CHALLENGE:\n${thesis}\n\nTask: Present a sharp ANTITHESIS (âš”ï¸). Highlight risks and provide a strong counter-perspective.`,
        "You are the Prosecutor. Be highly critical and analytical.",
        MODELS.fastWorker // Prosecutor iÃ§in fallback
      );

      const synthesis = await callModel(
        MODELS.judge,
        `User Question: ${lastMessage}\n\nğŸ›¡ï¸ THESIS:\n${thesis}\n\nâš”ï¸ ANTITHESIS:\n${antithesis}\n\nTask: You are the High Judge. Provide the final SYNTHESIS (â—†). Weigh both arguments, resolve the conflict, and provide the most balanced and definitive answer.`,
        "You are the High Judge. Be wise, balanced, and decisive."
      );

      return NextResponse.json({
        tier: 'T3',
        responses: [
          { type: 'thesis', model: 'Claude', content: thesis },
          { type: 'antithesis', model: 'DeepSeek-R', content: antithesis },
          { type: 'synthesis', model: 'Claude Opus', content: synthesis }
        ]
      });
    }
    
    const response = await callModel(MODELS.fastWorker, lastMessage, undefined, MODELS.fastWorker);
    return NextResponse.json({
      tier: tier,
      responses: [{ type: 'normal', model: 'DeepSeek', content: response }]
    });
    
  } catch (error: any) {
    // Hata mesajÄ±nÄ± temizle ve kullanÄ±cÄ±ya gÃ¶ster
    let errorMessage = error.message || 'Bilinmeyen bir sunucu hatasÄ± oluÅŸtu.';
    
    // API Key hatasÄ± gibi hassas bilgileri temizle
    if (errorMessage.includes('Authorization')) {
      errorMessage = 'API Key HatasÄ±: OpenRouter API Key geÃ§ersiz veya eksik.';
    } else if (errorMessage.includes('HTTP Error 404')) {
      errorMessage = 'Model BulunamadÄ± HatasÄ±: KullanÄ±lan model ID\'si OpenRouter\'da mevcut deÄŸil.';
    } else if (errorMessage.includes('HTTP Error 429')) {
      errorMessage = 'HÄ±z Limiti HatasÄ±: Ã‡ok fazla istek gÃ¶nderildi. LÃ¼tfen bir sÃ¼re sonra tekrar deneyin.';
    } else if (errorMessage.includes('HTTP Error 400')) {
      errorMessage = 'GeÃ§ersiz Ä°stek HatasÄ±: Ä°stek formatÄ± veya parametreleri hatalÄ±.';
    } else if (errorMessage.includes('OpenRouter Error:')) {
      // OpenRouter'dan gelen spesifik hatayÄ± koru
      errorMessage = errorMessage.replace('OpenRouter Error: ', '');
    }

    return new NextResponse(JSON.stringify({ 
      error: errorMessage,
      type: 'error' // Frontend'in bu mesajÄ± hata olarak iÅŸlemesi iÃ§in
    }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
}
