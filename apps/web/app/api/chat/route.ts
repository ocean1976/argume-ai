import { NextRequest, NextResponse } from 'next/server'
import { MODELS } from '@/lib/models'
import { getModelName } from '@/lib/modelNames'
import { getTier } from '@/lib/orchestrator'

export const dynamic = 'force-dynamic'
export const runtime = 'edge'

async function callModel(modelId: string, prompt: string, systemPrompt?: string, fallbackModelId?: string): Promise<string> {
  const API_KEY = process.env.OPENROUTER_API_KEY || ''
  
  const modelsToTry = [modelId];
  if (fallbackModelId) {
    modelsToTry.push(fallbackModelId);
  }

  let lastError: Error | null = null;

  for (const currentModelId of modelsToTry) {
    try {
      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${API_KEY}`,
      'Content-Type': 'application/json',
      'HTTP-Referer': 'https://clashof.ai',
      'X-Title': 'Clash of AI'
    },
    body: JSON.stringify({
      model: modelId,
      messages: [
        ...(systemPrompt ? [{ role: 'system', content: systemPrompt }] : []),
        { role: 'user', content: prompt }
      ],
      stream: false,
    }),
  });
  
  const data = await response.json();

  if (!response.ok) {
    // OpenRouter'dan gelen hata mesajƒ±nƒ± yakala
    const errorMessage = data.error ? data.error.message : `HTTP Error ${response.status}`;
    throw new Error(`OpenRouter Error: ${errorMessage}`);
  }
  
  if (!data.choices || data.choices.length === 0) {
    throw new Error('OpenRouter Error: Model yanƒ±t vermedi veya bo≈ü bir se√ßim listesi d√∂nd√ºrd√º.');
  }

  return data.choices[0].message.content;
} catch (error: any) {
      lastError = error;
      console.error(`Model ${currentModelId} failed. Trying fallback if available. Error: ${error.message}`);
      // Eƒüer bu son denemeyse, hatayƒ± fƒ±rlat
      if (currentModelId === modelsToTry[modelsToTry.length - 1]) {
        throw lastError;
      }
      // Aksi takdirde, bir sonraki modele ge√ß
    }
  }

  // Bu kƒ±sma normalde ula≈üƒ±lmamalƒ±, ancak TypeScript'i mutlu etmek i√ßin
  if (lastError) {
    throw lastError;
  }
  throw new Error('T√ºm model denemeleri ba≈üarƒ±sƒ±z oldu.');
}

export async function POST(req: NextRequest) {
  try {
    const body = await req.json();
    const { messages } = body;
    const lastMessage = messages[messages.length - 1].content;
    
    const tier = getTier(lastMessage);
    
    if (tier === 'T1') {
      const response = await callModel(MODELS.fastWorker, lastMessage, undefined, MODELS.fastWorker); // T1'de fallback'e gerek yok, zaten en hƒ±zlƒ± model
      return NextResponse.json({
        tier: 'T1',
        responses: [{ type: 'normal', model: getModelName(MODELS.fastWorker), content: response }]
      });
    }
    
    if (tier === 'T2') {
      const mainResponse = await callModel(
        MODELS.architect, 
        lastMessage, 
        "You are the Architect. Provide a detailed and structured answer.",
        MODELS.fastWorker // Architect i√ßin fallback
      );
      
      const interjection = await callModel(
        MODELS.prosecutor,
        `User Question: ${lastMessage}\nArchitect's Answer: ${mainResponse}\n\nTask: Critically analyze the answer. If there is a mistake, a better approach, or a missing constraint, provide a VERY SHORT note (max 2 sentences). If the answer is perfect, reply ONLY with 'OK'.`,
        "You are the Prosecutor. Be critical and concise."
      );
      
        responses: [
          { type: 'normal', model: getModelName(MODELS.architect), content: mainResponse }
        ]];
      
      if (interjection.trim().toUpperCase() !== 'OK') {
        responses.push({ type: 'info', model: 'Prosecutor', content: interjection });
      }
      
      return NextResponse.json({ tier: 'T2', responses });
    }

    if (tier === 'T2.5') {
      const thesis = await callModel(
        MODELS.architect,
        lastMessage,
        "You are the Architect. Your role is to present a strong THESIS (üõ°Ô∏è). Provide a clear and well-supported argument.",
        MODELS.fastWorker // Architect i√ßin fallback
      );

      const antithesis = await callModel(
        MODELS.prosecutor,
        `User Question: ${lastMessage}\n\nüõ°Ô∏è THESIS TO CHALLENGE:\n${thesis}\n\nTask: Present a strong ANTITHESIS (‚öîÔ∏è). Do NOT repeat the thesis. Challenge its weaknesses and offer a compelling counter-argument.`,
        "You are the Prosecutor. Be sharp and provide a strong counter-view."
      );

      return NextResponse.json({
        tier: 'T2.5',
        responses: [
          { type: 'thesis', model: getModelName(MODELS.architect), content: thesis },
          { type: 'antithesis', model: getModelName(MODELS.prosecutor), content: antithesis }
        ]
      });
    }

    if (tier === 'T3') {
      const thesis = await callModel(
        MODELS.architect,
        lastMessage,
        "You are the Architect. Present a deep and comprehensive THESIS (üõ°Ô∏è). Consider all major factors.",
        MODELS.fastWorker // Architect i√ßin fallback
      );

      const antithesis = await callModel(
        MODELS.prosecutor,
        `User Question: ${lastMessage}\n\nüõ°Ô∏è THESIS TO CHALLENGE:\n${thesis}\n\nTask: Present a sharp ANTITHESIS (‚öîÔ∏è). Highlight risks and provide a strong counter-perspective.`,
        "You are the Prosecutor. Be highly critical and analytical.",
        MODELS.fastWorker // Prosecutor i√ßin fallback
      );

      const synthesis = await callModel(
        MODELS.judge,
        `User Question: ${lastMessage}\n\nüõ°Ô∏è THESIS:\n${thesis}\n\n‚öîÔ∏è ANTITHESIS:\n${antithesis}\n\nTask: You are the High Judge. Provide the final SYNTHESIS (‚óÜ). Weigh both arguments, resolve the conflict, and provide the most balanced and definitive answer.`,
        "You are the High Judge. Be wise, balanced, and decisive."
      );

      return NextResponse.json({
        tier: 'T3',
        responses: [
          { type: 'thesis', model: getModelName(MODELS.architect), content: thesis },
          { type: 'antithesis', model: getModelName(MODELS.prosecutor), content: antithesis },
          { type: 'synthesis', model: getModelName(MODELS.judge), content: synthesis }
        ]
      });
    }
    
    const response = await callModel(MODELS.fastWorker, lastMessage, undefined, MODELS.fastWorker);
    return NextResponse.json({
      tier: tier,
      responses: [{ type: 'normal', model: getModelName(MODELS.fastWorker), content: response }]
    });
    
  } catch (error: any) {
    // Hata mesajƒ±nƒ± temizle ve kullanƒ±cƒ±ya g√∂ster
    let errorMessage = error.message || 'Bilinmeyen bir sunucu hatasƒ± olu≈ütu.';
    
    // API Key hatasƒ± gibi hassas bilgileri temizle
    if (errorMessage.includes('Authorization')) {
      errorMessage = 'API Key Hatasƒ±: OpenRouter API Key ge√ßersiz veya eksik.';
    } else if (errorMessage.includes('HTTP Error 404')) {
      errorMessage = 'Model Bulunamadƒ± Hatasƒ±: Kullanƒ±lan model ID\'si OpenRouter\'da mevcut deƒüil.';
    } else if (errorMessage.includes('HTTP Error 429')) {
      errorMessage = 'Hƒ±z Limiti Hatasƒ±: √áok fazla istek g√∂nderildi. L√ºtfen bir s√ºre sonra tekrar deneyin.';
    } else if (errorMessage.includes('HTTP Error 400')) {
      errorMessage = 'Ge√ßersiz ƒ∞stek Hatasƒ±: ƒ∞stek formatƒ± veya parametreleri hatalƒ±.';
    } else if (errorMessage.includes('OpenRouter Error:')) {
      // OpenRouter'dan gelen spesifik hatayƒ± koru
      errorMessage = errorMessage.replace('OpenRouter Error: ', '');
    }

    return new NextResponse(JSON.stringify({ 
      error: errorMessage,
      type: 'error' // Frontend'in bu mesajƒ± hata olarak i≈ülemesi i√ßin
    }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
}
